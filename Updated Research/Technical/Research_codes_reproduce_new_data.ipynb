{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a181cd30",
   "metadata": {},
   "source": [
    "# Spam Detection Project Reproduce new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "cf0eb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import patsy\n",
    "from statsmodels.discrete.discrete_model import ProbitResults, LogitResults\n",
    "os.chdir(r\"C:\\Users\\serei\\Desktop\\Untitled Folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32a25f",
   "metadata": {},
   "source": [
    "The analysis will be conducted using word frequencies from the old research as well as a new word list from the new datsaset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14892edf",
   "metadata": {},
   "source": [
    "## New Data New Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497ff39",
   "metadata": {},
   "source": [
    "Import and prepare the dataset for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fb84e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"new_data_new_words.csv\")\n",
    "spam.dropna(inplace = True)\n",
    "\n",
    "#Renaming character columns to a less error-prone form\n",
    "spam.rename(columns = {'$':'dollar',\n",
    "                       '!': 'exclamation',\n",
    "                      \"#\": \"hashtag\",\n",
    "                       \"(\":\"parenthesis\",\n",
    "                       \"[\": \"brackets\",\n",
    "                       \";\": \"semicolon\",\n",
    "                       \"â‚¬\": \"euro\",\n",
    "                       \"@\": \"at\", \n",
    "                       \"?\": \"question\"\n",
    "                      }, inplace = True)\n",
    "\n",
    "#Drop columns not neccessary to the analysis\n",
    "spam.drop(columns=['Unnamed: 0', 'processed_text', 'word_count'], inplace = True)\n",
    "\n",
    "#Rename columns to include word_freq\n",
    "column_names = spam.columns.tolist()\n",
    "new_column_names = ['spam'] + ['word_freq_' + column if column != 'spam' else column for column in column_names[1:]]\n",
    "\n",
    "spam.rename(columns=dict(zip(column_names, new_column_names)), inplace=True)\n",
    "\n",
    "#Convert the dependent variable to a numeric one\n",
    "spam['spam'] = spam['spam'].replace({\n",
    "    'spam': 1,\n",
    "    'ham': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f2f3f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       spam  word_freq_u  word_freq_call  word_freq_get  word_freq_ur  \\\n",
       "0        0          0.0            0.00            0.0           0.0   \n",
       "1        0          0.0            0.00            0.0           0.0   \n",
       "2        1          0.0            0.00            0.0           0.0   \n",
       "3        0          0.0            0.00            0.0           0.0   \n",
       "4        0          0.0            0.00            0.0           0.0   \n",
       "...    ...          ...             ...            ...           ...   \n",
       "5567     1          0.0            0.08            0.0           0.0   \n",
       "5568     0          0.0            0.00            0.0           0.0   \n",
       "5569     0          0.0            0.00            0.0           0.0   \n",
       "5570     0          0.0            0.00            0.0           0.0   \n",
       "5571     0          0.0            0.00            0.0           0.0   \n",
       "\n",
       "      word_freq_gt  word_freq_lt  word_freq_go  word_freq_free  \\\n",
       "0              0.0           0.0      0.150000        0.000000   \n",
       "1              0.0           0.0      0.000000        0.000000   \n",
       "2              0.0           0.0      0.000000        0.133333   \n",
       "3              0.0           0.0      0.000000        0.000000   \n",
       "4              0.0           0.0      0.333333        0.000000   \n",
       "...            ...           ...           ...             ...   \n",
       "5567           0.0           0.0      0.000000        0.000000   \n",
       "5568           0.0           0.0      0.000000        0.000000   \n",
       "5569           0.0           0.0      0.000000        0.000000   \n",
       "5570           0.0           0.0      0.000000        0.285714   \n",
       "5571           0.0           0.0      0.000000        0.000000   \n",
       "\n",
       "      word_freq_know  ...  word_freq_hi  word_freq_please  word_freq_pls  \\\n",
       "0                0.0  ...           0.0               0.0            0.0   \n",
       "1                0.0  ...           0.0               0.0            0.0   \n",
       "2                0.0  ...           0.0               0.0            0.0   \n",
       "3                0.0  ...           0.0               0.0            0.0   \n",
       "4                0.0  ...           0.0               0.0            0.0   \n",
       "...              ...  ...           ...               ...            ...   \n",
       "5567             0.0  ...           0.0               0.0            0.0   \n",
       "5568             0.0  ...           0.0               0.0            0.0   \n",
       "5569             0.0  ...           0.0               0.0            0.0   \n",
       "5570             0.0  ...           0.0               0.0            0.0   \n",
       "5571             0.0  ...           0.0               0.0            0.0   \n",
       "\n",
       "      word_freq_make  word_freq_dollar  word_freq_euro  word_freq_exclamation  \\\n",
       "0                0.0               0.0             0.0               0.000000   \n",
       "1                0.0               0.0             0.0               0.000000   \n",
       "2                0.0               0.0             0.0               0.000000   \n",
       "3                0.0               0.0             0.0               0.000000   \n",
       "4                0.0               0.0             0.0               0.000000   \n",
       "...              ...               ...             ...                    ...   \n",
       "5567             0.0               0.0             0.0               0.090909   \n",
       "5568             0.0               0.0             0.0               0.000000   \n",
       "5569             0.0               0.0             0.0               0.000000   \n",
       "5570             0.0               0.0             0.0               0.000000   \n",
       "5571             0.0               0.0             0.0               0.000000   \n",
       "\n",
       "      word_freq_at  word_freq_question  word_freq_digit_count  \n",
       "0              0.0            0.000000                      0  \n",
       "1              0.0            0.000000                      0  \n",
       "2              0.0            0.000000                     25  \n",
       "3              0.0            0.000000                      0  \n",
       "4              0.0            0.000000                      0  \n",
       "...            ...                 ...                    ...  \n",
       "5567           0.0            0.000000                     21  \n",
       "5568           0.0            0.083333                      0  \n",
       "5569           0.0            0.083333                      0  \n",
       "5570           0.0            0.000000                      0  \n",
       "5571           0.0            0.000000                      0  \n",
       "\n",
       "[5572 rows x 57 columns]>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad86a39",
   "metadata": {},
   "source": [
    "Very low variances in independent variables cause errors in the models. We set a treshold for the variances of the columns and keep only the columns that can be included in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a1341dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam                      0.116111\n",
       "word_freq_call            0.005306\n",
       "word_freq_get             0.003488\n",
       "word_freq_ur              0.003405\n",
       "word_freq_gt              0.007387\n",
       "word_freq_lt              0.009940\n",
       "word_freq_go              0.004034\n",
       "word_freq_free            0.004759\n",
       "word_freq_come            0.003268\n",
       "word_freq_day             0.003685\n",
       "word_freq_time            0.003465\n",
       "word_freq_text            0.004684\n",
       "word_freq_love            0.003443\n",
       "word_freq_send            0.003109\n",
       "word_freq_need            0.003308\n",
       "word_freq_going           0.004255\n",
       "word_freq_sorry           0.004954\n",
       "word_freq_still           0.004305\n",
       "word_freq_take            0.003129\n",
       "word_freq_da              0.004420\n",
       "word_freq_dont            0.003515\n",
       "word_freq_later           0.007791\n",
       "word_freq_exclamation     0.003834\n",
       "word_freq_digit_count    38.995783\n",
       "dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = spam.var()\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.003\n",
    "\n",
    "# Filter columns based on variance threshold\n",
    "filtered_columns = variance[variance >= threshold].index\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "spam = spam[filtered_columns]\n",
    "\n",
    "spam.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595875b",
   "metadata": {},
   "source": [
    "Let us check the distribution of spam and non-spam mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea06ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_count = spam[\"spam\"].value_counts()\n",
    "perc_yes = round(spam_count[1] / len(spam) * 100, 2)\n",
    "perc_no = round(spam_count[0] / len(spam) * 100, 2)\n",
    "\n",
    "plt.bar([\"Non-spam\", \"Spam\"], spam_count, color=[\"#31d64f\", \"#ed3b3b\"])\n",
    "plt.title(\"Number of spam/non-spam mails\")\n",
    "plt.xlabel(\"Type of mail\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Non-spam\", \"Spam\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d25fc9",
   "metadata": {},
   "source": [
    "## Start from the most general model that contains all explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b02c215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spam ~ \" + \" + \".join(spam.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffe5b2",
   "metadata": {},
   "source": [
    "### Probit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0f4781df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084801\n",
      "         Iterations: 35\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5548\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7848\n",
      "Time:                        12:51:21   Log-Likelihood:                -472.51\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.2321      0.061    -36.431      0.000      -2.352      -2.112\n",
      "word_freq_call           -3.0682      1.010     -3.037      0.002      -5.048      -1.088\n",
      "word_freq_get            -0.1846      0.816     -0.226      0.821      -1.783       1.414\n",
      "word_freq_ur             -1.1577      0.835     -1.387      0.166      -2.794       0.479\n",
      "word_freq_gt            -14.9780   7.81e+05  -1.92e-05      1.000   -1.53e+06    1.53e+06\n",
      "word_freq_lt            -38.8083   6.73e+05  -5.77e-05      1.000   -1.32e+06    1.32e+06\n",
      "word_freq_go             -0.2868      0.757     -0.379      0.705      -1.771       1.197\n",
      "word_freq_free            3.0220      0.419      7.218      0.000       2.201       3.843\n",
      "word_freq_come           -0.5091      1.095     -0.465      0.642      -2.655       1.636\n",
      "word_freq_day            -0.3404      0.797     -0.427      0.669      -1.902       1.222\n",
      "word_freq_time           -0.8513      1.052     -0.809      0.418      -2.914       1.211\n",
      "word_freq_text            1.9207      0.347      5.528      0.000       1.240       2.602\n",
      "word_freq_love           -2.2725      1.616     -1.406      0.160      -5.440       0.895\n",
      "word_freq_send            0.5875      0.701      0.838      0.402      -0.787       1.961\n",
      "word_freq_need           -1.4221      1.381     -1.030      0.303      -4.129       1.285\n",
      "word_freq_going          -1.8651      1.649     -1.131      0.258      -5.097       1.367\n",
      "word_freq_sorry          -3.8238      2.008     -1.904      0.057      -7.760       0.112\n",
      "word_freq_still          -4.7817      3.544     -1.349      0.177     -11.728       2.165\n",
      "word_freq_take           -0.6396      1.117     -0.572      0.567      -2.830       1.550\n",
      "word_freq_da            -48.1537   1.42e+04     -0.003      0.997   -2.79e+04    2.78e+04\n",
      "word_freq_dont           -0.2995      0.984     -0.304      0.761      -2.228       1.629\n",
      "word_freq_later         -61.9383   8.22e+04     -0.001      0.999   -1.61e+05    1.61e+05\n",
      "word_freq_exclamation     2.3871      0.507      4.705      0.000       1.393       3.382\n",
      "word_freq_digit_count     0.3589      0.016     23.073      0.000       0.328       0.389\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.19 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "myprobit = sm.Probit.from_formula(formula, data=spam).fit()\n",
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a94060",
   "metadata": {},
   "source": [
    "### Logit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "69db3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084299\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5548\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.7861\n",
      "Time:                        12:51:23   Log-Likelihood:                -469.72\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -4.2063      0.143    -29.436      0.000      -4.486      -3.926\n",
      "word_freq_call           -5.9051      2.032     -2.906      0.004      -9.887      -1.923\n",
      "word_freq_get            -0.1263      1.687     -0.075      0.940      -3.432       3.180\n",
      "word_freq_ur             -3.6651      1.709     -2.145      0.032      -7.015      -0.316\n",
      "word_freq_gt            -52.1552   1.26e+05     -0.000      1.000   -2.47e+05    2.47e+05\n",
      "word_freq_lt            -70.7824   1.08e+05     -0.001      0.999   -2.12e+05    2.12e+05\n",
      "word_freq_go             -0.7489      1.788     -0.419      0.675      -4.253       2.755\n",
      "word_freq_free            5.6490      0.834      6.770      0.000       4.013       7.285\n",
      "word_freq_come           -1.6813      2.853     -0.589      0.556      -7.272       3.910\n",
      "word_freq_day            -0.5304      1.635     -0.324      0.746      -3.735       2.674\n",
      "word_freq_time           -2.1441      2.459     -0.872      0.383      -6.963       2.675\n",
      "word_freq_text            3.6967      0.615      6.011      0.000       2.491       4.902\n",
      "word_freq_love           -6.3427      4.199     -1.510      0.131     -14.574       1.888\n",
      "word_freq_send            1.5300      1.418      1.079      0.281      -1.250       4.310\n",
      "word_freq_need           -4.3002      4.018     -1.070      0.285     -12.176       3.576\n",
      "word_freq_going          -6.3393      5.609     -1.130      0.258     -17.333       4.654\n",
      "word_freq_sorry          -6.5950      3.628     -1.818      0.069     -13.705       0.515\n",
      "word_freq_still          -9.5567      7.176     -1.332      0.183     -23.622       4.508\n",
      "word_freq_take           -2.7223      3.339     -0.815      0.415      -9.267       3.822\n",
      "word_freq_da           -100.8663   1725.577     -0.058      0.953   -3482.936    3281.203\n",
      "word_freq_dont           -0.9747      2.531     -0.385      0.700      -5.935       3.986\n",
      "word_freq_later        -149.2632   1.54e+04     -0.010      0.992   -3.04e+04    3.01e+04\n",
      "word_freq_exclamation     4.5261      0.975      4.640      0.000       2.614       6.438\n",
      "word_freq_digit_count     0.7350      0.038     19.591      0.000       0.661       0.809\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.16 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula, data=spam).fit()\n",
    "print(mylogit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433aef44",
   "metadata": {},
   "source": [
    "# Significance test of models\n",
    "\n",
    "Both models p-values are 0, so null hypothesis can be rejected. It means that the model`s coefficients are jointly significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3af6d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probit likelihood ratio test p-value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fb8447e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 6\n",
      "Logit likelihood ratio test p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab87c0",
   "metadata": {},
   "source": [
    "## Stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f50e6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_gt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084816\n",
      "         Iterations: 35\n",
      "991.1940869610173\n",
      "word_freq_da\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.085715\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.2063848097096\n",
      "word_freq_lt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.090247\n",
      "         Iterations: 35\n",
      "1047.7131104852485\n",
      "word_freq_later\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090668\n",
      "         Iterations 10\n",
      "1050.4072904922891\n",
      "word_freq_get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090669\n",
      "         Iterations 10\n",
      "1048.4154478192277\n",
      "word_freq_go\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090671\n",
      "         Iterations 10\n",
      "1046.4426142168152\n",
      "word_freq_dont\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090676\n",
      "         Iterations 10\n",
      "1044.4917974879752\n",
      "word_freq_day\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090683\n",
      "         Iterations 10\n",
      "1042.5711276093857\n",
      "word_freq_take\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090704\n",
      "         Iterations 10\n",
      "1040.8103242756306\n",
      "word_freq_come\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090728\n",
      "         Iterations 10\n",
      "1039.0676621119137\n",
      "word_freq_send\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090776\n",
      "         Iterations 10\n",
      "1037.6113412700504\n",
      "word_freq_time\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090851\n",
      "         Iterations 10\n",
      "1036.4489011521632\n",
      "word_freq_need\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.090967\n",
      "         Iterations 10\n",
      "1035.7413734538893\n",
      "word_freq_going\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091161\n",
      "         Iterations 10\n",
      "1035.8955467500268\n",
      "word_freq_ur\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091284\n",
      "         Iterations 10\n",
      "1035.2711955708116\n",
      "word_freq_still\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091649\n",
      "         Iterations 10\n",
      "1037.3409034703457\n",
      "word_freq_love\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091952\n",
      "         Iterations 10\n",
      "1038.7099279546596\n",
      "word_freq_sorry\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092441\n",
      "         Iterations 8\n",
      "1042.1626013693967\n"
     ]
    }
   ],
   "source": [
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "09ce8b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_gt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.084316\n",
      "         Iterations: 35\n",
      "985.6201246859478\n",
      "word_freq_da\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.085355\n",
      "         Iterations: 35\n",
      "995.1955540349777\n",
      "word_freq_lt\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.090632\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1810: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051.9988162051395\n",
      "word_freq_later\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091062\n",
      "         Iterations 11\n",
      "1054.7944439196922\n",
      "word_freq_get\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091063\n",
      "         Iterations 11\n",
      "1052.801501186288\n",
      "word_freq_day\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091064\n",
      "         Iterations 11\n",
      "1050.8192514721536\n",
      "word_freq_go\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091069\n",
      "         Iterations 11\n",
      "1048.8679678238063\n",
      "word_freq_dont\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091080\n",
      "         Iterations 11\n",
      "1046.9987516065285\n",
      "word_freq_come\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091120\n",
      "         Iterations 11\n",
      "1045.4394448721005\n",
      "word_freq_take\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091180\n",
      "         Iterations 11\n",
      "1044.1081245022165\n",
      "word_freq_time\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091261\n",
      "         Iterations 11\n",
      "1043.009973580889\n",
      "word_freq_send\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091332\n",
      "         Iterations 11\n",
      "1041.8052523645847\n",
      "word_freq_need\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091494\n",
      "         Iterations 11\n",
      "1041.609751512806\n",
      "word_freq_going\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.091765\n",
      "         Iterations 11\n",
      "1042.6304617980154\n",
      "word_freq_still\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092112\n",
      "         Iterations 10\n",
      "1044.4921206580443\n",
      "word_freq_love\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092502\n",
      "         Iterations 10\n",
      "1046.8384023261972\n",
      "word_freq_sorry\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092979\n",
      "         Iterations 9\n",
      "1050.1593483933707\n",
      "word_freq_ur\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.093262\n",
      "         Iterations 9\n",
      "1051.313098615637\n"
     ]
    }
   ],
   "source": [
    "p_logit = mylogit.pvalues\n",
    "spam_temp_logit = spam.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3defa",
   "metadata": {},
   "source": [
    "## Link test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d0f51e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linktest_probit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.probit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def linktest_logit(model):\n",
    "    \"\"\"\n",
    "    Function to perform linktest on a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "    - model: logistic regression model object\n",
    "    \n",
    "    Returns:\n",
    "    - aux_reg: auxiliary regression model object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    y = model.model.endog\n",
    "    pred = model.predict()\n",
    "    pred = np.clip(pred, 1e-12, 1 - 1e-12)\n",
    "    yhat = np.log(pred/(1-pred))\n",
    "    yhat2 = yhat**2\n",
    "\n",
    "    # Add constant column to predictor variables\n",
    "    X = np.column_stack((np.ones_like(y), yhat, yhat2))\n",
    "\n",
    "    # Remove rows with missing or infinite values\n",
    "    valid_idx = np.isfinite(X).all(axis=1)\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    # Fit the binomial regression model\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(link=sm.genmod.families.links.logit()))\n",
    "    result = model.fit()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "70c9b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -498.75\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       997.50\n",
      "Time:                        12:51:40   Pearson chi2:                 6.00e+04\n",
      "No. Iterations:                    10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1035      0.068      1.533      0.125      -0.029       0.236\n",
      "x1             0.4932      0.017     28.757      0.000       0.460       0.527\n",
      "x2            -0.0149      0.001    -16.346      0.000      -0.017      -0.013\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3c9fd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -506.88\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       1013.8\n",
      "Time:                        12:51:42   Pearson chi2:                 4.31e+03\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2302      0.131      1.752      0.080      -0.027       0.488\n",
      "x1             0.9447      0.036     26.424      0.000       0.875       1.015\n",
      "x2            -0.0339      0.003    -11.359      0.000      -0.040      -0.028\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Linktest for logit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c1348",
   "metadata": {},
   "source": [
    "### Interaction terms\n",
    "Adding interaction terms and deleting insignificant ones for probit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f8770ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'word_freq_call', 'word_freq_get', 'word_freq_ur',\n",
       "       'word_freq_gt', 'word_freq_lt', 'word_freq_go', 'word_freq_free',\n",
       "       'word_freq_come', 'word_freq_day', 'word_freq_time', 'word_freq_text',\n",
       "       'word_freq_love', 'word_freq_send', 'word_freq_need', 'word_freq_going',\n",
       "       'word_freq_sorry', 'word_freq_still', 'word_freq_take', 'word_freq_da',\n",
       "       'word_freq_dont', 'word_freq_later', 'word_freq_exclamation',\n",
       "       'word_freq_digit_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3e294c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.339735\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~  word_freq_free * word_freq_exclamation  + word_freq_send \"\n",
    "myprobit = sm.Probit.from_formula(formula_interactions, data=spam).fit()\n",
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = formula_interactions\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "622d1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.340333\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula_interactions, data=spam).fit()\n",
    "p_logit = mylogit.pvalues\n",
    "spam_temp_probit = spam.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = formula_interactions\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ea06bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probit likelihood ratio test p-value: 1.2652102247814454e-133\n"
     ]
    }
   ],
   "source": [
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b9fe58cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit likelihood ratio test p-value: 3.567628329112654e-132\n"
     ]
    }
   ],
   "source": [
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "093ce782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>word_freq_call</th>\n",
       "      <th>word_freq_get</th>\n",
       "      <th>word_freq_ur</th>\n",
       "      <th>word_freq_gt</th>\n",
       "      <th>word_freq_lt</th>\n",
       "      <th>word_freq_go</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_come</th>\n",
       "      <th>word_freq_day</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_need</th>\n",
       "      <th>word_freq_going</th>\n",
       "      <th>word_freq_sorry</th>\n",
       "      <th>word_freq_still</th>\n",
       "      <th>word_freq_take</th>\n",
       "      <th>word_freq_da</th>\n",
       "      <th>word_freq_dont</th>\n",
       "      <th>word_freq_later</th>\n",
       "      <th>word_freq_exclamation</th>\n",
       "      <th>word_freq_digit_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.00000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.134063</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.01701</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.022531</td>\n",
       "      <td>2.371859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340751</td>\n",
       "      <td>0.072845</td>\n",
       "      <td>0.059060</td>\n",
       "      <td>0.058349</td>\n",
       "      <td>0.08595</td>\n",
       "      <td>0.099698</td>\n",
       "      <td>0.063513</td>\n",
       "      <td>0.068988</td>\n",
       "      <td>0.057165</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057515</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.070386</td>\n",
       "      <td>0.065609</td>\n",
       "      <td>0.055939</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>0.088268</td>\n",
       "      <td>0.061922</td>\n",
       "      <td>6.244660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              spam  word_freq_call  word_freq_get  word_freq_ur  word_freq_gt  \\\n",
       "count  5572.000000     5572.000000    5572.000000   5572.000000    5572.00000   \n",
       "mean      0.134063        0.018911       0.012528      0.011000       0.01701   \n",
       "std       0.340751        0.072845       0.059060      0.058349       0.08595   \n",
       "min       0.000000        0.000000       0.000000      0.000000       0.00000   \n",
       "25%       0.000000        0.000000       0.000000      0.000000       0.00000   \n",
       "50%       0.000000        0.000000       0.000000      0.000000       0.00000   \n",
       "75%       0.000000        0.000000       0.000000      0.000000       0.00000   \n",
       "max       1.000000        1.000000       1.000000      1.000000       1.00000   \n",
       "\n",
       "       word_freq_lt  word_freq_go  word_freq_free  word_freq_come  \\\n",
       "count   5572.000000   5572.000000     5572.000000     5572.000000   \n",
       "mean       0.019770      0.012389        0.011804        0.009796   \n",
       "std        0.099698      0.063513        0.068988        0.057165   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        0.000000      0.000000        0.000000        0.000000   \n",
       "50%        0.000000      0.000000        0.000000        0.000000   \n",
       "75%        0.000000      0.000000        0.000000        0.000000   \n",
       "max        1.000000      1.000000        1.000000        1.000000   \n",
       "\n",
       "       word_freq_day  ...  word_freq_need  word_freq_going  word_freq_sorry  \\\n",
       "count    5572.000000  ...     5572.000000      5572.000000      5572.000000   \n",
       "mean        0.010405  ...        0.008463         0.009878         0.010328   \n",
       "std         0.060704  ...        0.057515         0.065233         0.070386   \n",
       "min         0.000000  ...        0.000000         0.000000         0.000000   \n",
       "25%         0.000000  ...        0.000000         0.000000         0.000000   \n",
       "50%         0.000000  ...        0.000000         0.000000         0.000000   \n",
       "75%         0.000000  ...        0.000000         0.000000         0.000000   \n",
       "max         1.000000  ...        1.000000         1.000000         1.000000   \n",
       "\n",
       "       word_freq_still  word_freq_take  word_freq_da  word_freq_dont  \\\n",
       "count      5572.000000     5572.000000   5572.000000     5572.000000   \n",
       "mean          0.009236        0.007626      0.009253        0.007779   \n",
       "std           0.065609        0.055939      0.066481        0.059286   \n",
       "min           0.000000        0.000000      0.000000        0.000000   \n",
       "25%           0.000000        0.000000      0.000000        0.000000   \n",
       "50%           0.000000        0.000000      0.000000        0.000000   \n",
       "75%           0.000000        0.000000      0.000000        0.000000   \n",
       "max           1.000000        1.000000      1.000000        1.000000   \n",
       "\n",
       "       word_freq_later  word_freq_exclamation  word_freq_digit_count  \n",
       "count      5572.000000            5572.000000            5572.000000  \n",
       "mean          0.012394               0.022531               2.371859  \n",
       "std           0.088268               0.061922               6.244660  \n",
       "min           0.000000               0.000000               0.000000  \n",
       "25%           0.000000               0.000000               0.000000  \n",
       "50%           0.000000               0.000000               0.000000  \n",
       "75%           0.000000               0.000000               1.000000  \n",
       "max           1.000000               1.000000              47.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253fcb9c",
   "metadata": {},
   "source": [
    "## Recration from line 267 from R code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "add39fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                               0.000000e+00\n",
      "word_freq_free                          1.427736e-26\n",
      "word_freq_exclamation                   1.769530e-50\n",
      "word_freq_free:word_freq_exclamation    1.710706e-05\n",
      "word_freq_send                          1.309985e-03\n",
      "word_freq_get                           3.225381e-02\n",
      "word_freq_ur                            9.726582e-05\n",
      "word_freq_get:word_freq_ur              8.443402e-01\n",
      "word_freq_still                         7.665286e-03\n",
      "word_freq_sorry                         1.253296e-03\n",
      "dtype: float64\n",
      "Intercept                               0.000000e+00\n",
      "word_freq_free                          1.892276e-34\n",
      "word_freq_exclamation                   2.398555e-58\n",
      "word_freq_free:word_freq_exclamation    3.194177e-08\n",
      "word_freq_send                          8.336926e-04\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~  word_freq_free * word_freq_exclamation  + word_freq_send + word_freq_get*word_freq_ur + word_freq_still + word_freq_sorry\"\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam, family=sm.families.Binomial(sm.genmod.families.links.logit())).fit()\n",
    "\n",
    "p = mylogit.pvalues\n",
    "print(p)\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam, family=sm.families.Binomial(sm.genmod.families.links.probit())).fit()\n",
    "\n",
    "p = myprobit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f2cf4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        myprobit = sm.Probit(spam['spam'], X).fit()\n",
    "\n",
    "        print(myprobit.summary())\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "22e17725",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        mylogit = sm.GLM(spam['spam'], X, family=sm.families.Binomial(sm.families.links.logit())).fit()\n",
    "\n",
    "        print(mylogit.summary())\n",
    "        p = mylogit.pvalues\n",
    "        print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24da0f9",
   "metadata": {},
   "source": [
    "### Goodnes of fit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "85d060a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Goodness-of-Fit Test:\n",
      "Logit | Deviance:  3724.4546891739974\n"
     ]
    }
   ],
   "source": [
    "gof_results = mylogit.deviance\n",
    "print(\"Logit | Goodness-of-Fit Test:\")\n",
    "print(\"Logit | Deviance: \", gof_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "21627eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Pseudo R-squared:  0.15182947635330202\n",
      "Probit | Pseudo R-squared:  0.13781243162991275\n"
     ]
    }
   ],
   "source": [
    "pseudo_r2 = 1 - (mylogit.llf / mylogit.llnull)\n",
    "print(\"Logit | Pseudo R-squared: \", pseudo_r2)\n",
    "\n",
    "pseudo_r2 = 1 - (myprobit.llf / myprobit.llnull)\n",
    "print(\"Probit | Pseudo R-squared: \", pseudo_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7e1f585a",
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'word_freq_sorry' is not defined\n    spam ~  word_freq_free * word_freq_exclamation  + word_freq_send + word_freq_get*word_freq_ur + word_freq_still + word_freq_sorry\n                                                                                                                      ^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0m\u001b[0;32m    166\u001b[0m                                             + self._namespaces))\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_freq_sorry' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5192/4237911004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculating marginal effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmeff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_interactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspam_previous_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Probit | Marginal Effects:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0m\u001b[0;32m    170\u001b[0m                                   missing=missing)\n\u001b[0;32m    171\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0m\u001b[0;32m     64\u001b[0m                                NA_action=na_action)\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \"\"\"\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0m\u001b[0;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0m\u001b[0;32m    165\u001b[0m                                       NA_action)\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         return design_matrix_builders([formula_like.lhs_termlist,\n\u001b[0m\u001b[0;32m     67\u001b[0m                                        formula_like.rhs_termlist],\n\u001b[0;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;31m# on some data to find out what type of data they return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     (num_column_counts,\n\u001b[1;32m--> 693\u001b[1;33m      \u001b[0mcat_levels_contrasts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_examine_factor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_factors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[0m\u001b[0;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                           data)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36m_eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0minner_namespace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVarLookupDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"transforms\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         return call_and_wrap_exc(\"Error evaluating factor\",\n\u001b[0m\u001b[0;32m    548\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_env\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                  origin)\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raise new_exc from e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'word_freq_sorry' is not defined\n    spam ~  word_freq_free * word_freq_exclamation  + word_freq_send + word_freq_get*word_freq_ur + word_freq_still + word_freq_sorry\n                                                                                                                      ^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "# Calculating marginal effects\n",
    "meff = smf.probit(formula_interactions, data=spam_previous_words).fit()\n",
    "print(\"Probit | Marginal Effects:\")\n",
    "print(meff.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbb059",
   "metadata": {},
   "source": [
    "# New Data Old Words\n",
    "\n",
    "In this part of the analysis we will try to recreate the previous research on the new data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe56c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_previous_words = pd.read_csv(\"new_data_old_words.csv\")\n",
    "spam_previous_words.dropna(inplace = True)\n",
    "\n",
    "#Renaming character columns to a less error-prone form\n",
    "spam_previous_words.rename(columns = {'$':'dollar',\n",
    "                       '!': 'exclamation',\n",
    "                      \"#\": \"hashtag\",\n",
    "                       \"(\":\"parenthesis\",\n",
    "                       \"[\": \"brackets\",\n",
    "                       \";\": \"semicolon\",\n",
    "                       \"â‚¬\": \"euro\",\n",
    "                       \"@\": \"at\", \n",
    "                       \"?\": \"question\"\n",
    "                      }, inplace = True)\n",
    "\n",
    "#Drop columns not neccessary to the analysis\n",
    "spam_previous_words.drop(columns=['Unnamed: 0', 'processed_text', 'word_count'], inplace = True)\n",
    "\n",
    "#Rename columns to include word_freq\n",
    "column_names = spam_previous_words.columns.tolist()\n",
    "new_column_names = ['spam'] + ['word_freq_' + column if column != 'spam' else column for column in column_names[1:]]\n",
    "\n",
    "spam_previous_words.rename(columns=dict(zip(column_names, new_column_names)), inplace=True)\n",
    "\n",
    "#Convert the dependent variable to a numeric one\n",
    "spam_previous_words['spam'] = spam_previous_words['spam'].replace({\n",
    "    'spam': 1,\n",
    "    'ham': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f5a358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       spam  word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0        0             0.0                0.0           0.00           0.0   \n",
       "1        0             0.0                0.0           0.00           0.0   \n",
       "2        1             0.0                0.0           0.00           0.0   \n",
       "3        0             0.0                0.0           0.00           0.0   \n",
       "4        0             0.0                0.0           0.00           0.0   \n",
       "...    ...             ...                ...            ...           ...   \n",
       "5567     1             0.0                0.0           0.04           0.0   \n",
       "5568     0             0.0                0.0           0.00           0.0   \n",
       "5569     0             0.0                0.0           0.00           0.0   \n",
       "5570     0             0.0                0.0           0.00           0.0   \n",
       "5571     0             0.0                0.0           0.00           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0               0.0        0.000000               0.0                 0.0   \n",
       "1               0.0        0.000000               0.0                 0.0   \n",
       "2               0.0        0.033333               0.0                 0.0   \n",
       "3               0.0        0.000000               0.0                 0.0   \n",
       "4               0.0        0.000000               0.0                 0.0   \n",
       "...             ...             ...               ...                 ...   \n",
       "5567            0.0        0.000000               0.0                 0.0   \n",
       "5568            0.0        0.000000               0.0                 0.0   \n",
       "5569            0.0        0.000000               0.0                 0.0   \n",
       "5570            0.0        0.000000               0.0                 0.0   \n",
       "5571            0.0        0.000000               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  ...  word_freq_re  word_freq_edu  word_freq_table  \\\n",
       "0                 0.0  ...      0.100000            0.0              0.0   \n",
       "1                 0.0  ...      0.000000            0.0              0.0   \n",
       "2                 0.0  ...      0.066667            0.0              0.0   \n",
       "3                 0.0  ...      0.090909            0.0              0.0   \n",
       "4                 0.0  ...      0.000000            0.0              0.0   \n",
       "...               ...  ...           ...            ...              ...   \n",
       "5567              0.0  ...      0.000000            0.0              0.0   \n",
       "5568              0.0  ...      0.000000            0.0              0.0   \n",
       "5569              0.0  ...      0.000000            0.0              0.0   \n",
       "5570              0.0  ...      0.142857            0.0              0.0   \n",
       "5571              0.0  ...      0.000000            0.0              0.0   \n",
       "\n",
       "      word_freq_conference  word_freq_semicolon  word_freq_parenthesis  \\\n",
       "0                      0.0                  0.0               0.000000   \n",
       "1                      0.0                  0.0               0.000000   \n",
       "2                      0.0                  0.0               0.033333   \n",
       "3                      0.0                  0.0               0.000000   \n",
       "4                      0.0                  0.0               0.000000   \n",
       "...                    ...                  ...                    ...   \n",
       "5567                   0.0                  0.0               0.000000   \n",
       "5568                   0.0                  0.0               0.000000   \n",
       "5569                   0.0                  0.0               0.000000   \n",
       "5570                   0.0                  0.0               0.000000   \n",
       "5571                   0.0                  0.0               0.000000   \n",
       "\n",
       "      word_freq_brackets  word_freq_exclamation  word_freq_dollar  \\\n",
       "0                    0.0                   0.00               0.0   \n",
       "1                    0.0                   0.00               0.0   \n",
       "2                    0.0                   0.00               0.0   \n",
       "3                    0.0                   0.00               0.0   \n",
       "4                    0.0                   0.00               0.0   \n",
       "...                  ...                    ...               ...   \n",
       "5567                 0.0                   0.04               0.0   \n",
       "5568                 0.0                   0.00               0.0   \n",
       "5569                 0.0                   0.00               0.0   \n",
       "5570                 0.0                   0.00               0.0   \n",
       "5571                 0.0                   0.00               0.0   \n",
       "\n",
       "      word_freq_hashtag  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "5567                0.0  \n",
       "5568                0.0  \n",
       "5569                0.0  \n",
       "5570                0.0  \n",
       "5571                0.0  \n",
       "\n",
       "[5572 rows x 55 columns]>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_previous_words.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451361ec",
   "metadata": {},
   "source": [
    "We once again remove the columns with very low variances to ensure that the selected models run smoothly. We decrease the treshold as the previously used words are less frequently found in the new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04796af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam                     0.116111\n",
       "word_freq_make           0.000206\n",
       "word_freq_all            0.002106\n",
       "word_freq_our            0.000249\n",
       "word_freq_free           0.000335\n",
       "word_freq_meeting        0.000171\n",
       "word_freq_re             0.005786\n",
       "word_freq_edu            0.000193\n",
       "word_freq_semicolon      0.000912\n",
       "word_freq_exclamation    0.002293\n",
       "word_freq_hashtag        0.000174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = spam_previous_words.var()\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.00017\n",
    "\n",
    "# Filter columns based on variance threshold\n",
    "filtered_columns = variance[variance >= threshold].index\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "spam_previous_words = spam_previous_words[filtered_columns]\n",
    "\n",
    "spam_previous_words.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3849ab8",
   "metadata": {},
   "source": [
    "## Start from the most general model that contains all explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "37cb1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"spam ~ \" + \" + \".join(spam_previous_words.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb5740",
   "metadata": {},
   "source": [
    "### Probit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ec0d46ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.346699\n",
      "         Iterations: 35\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5561\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1201\n",
      "Time:                        12:55:18   Log-Likelihood:                -1931.8\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                5.689e-107\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.3365      0.030    -44.156      0.000      -1.396      -1.277\n",
      "word_freq_make           -2.8613      2.004     -1.428      0.153      -6.788       1.066\n",
      "word_freq_all             3.4102      0.418      8.157      0.000       2.591       4.230\n",
      "word_freq_our            -1.5310      1.753     -0.873      0.383      -4.967       1.905\n",
      "word_freq_free           13.3079      0.943     14.117      0.000      11.460      15.156\n",
      "word_freq_meeting       -63.2651    258.498     -0.245      0.807    -569.913     443.382\n",
      "word_freq_re              0.6952      0.293      2.370      0.018       0.120       1.270\n",
      "word_freq_edu             0.0336      1.786      0.019      0.985      -3.467       3.534\n",
      "word_freq_semicolon     -15.5432      3.426     -4.536      0.000     -22.259      -8.828\n",
      "word_freq_exclamation     3.9516      0.382     10.334      0.000       3.202       4.701\n",
      "word_freq_hashtag         8.6956      5.876      1.480      0.139      -2.821      20.212\n",
      "=========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "myprobit = sm.Probit.from_formula(formula, data=spam_previous_words).fit()\n",
    "print(myprobit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113cccc",
   "metadata": {},
   "source": [
    "### Logit model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0cca8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.345718\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                          Logit   Df Residuals:                     5561\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                  0.1226\n",
      "Time:                        12:55:21   Log-Likelihood:                -1926.3\n",
      "converged:                      False   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.607e-109\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.2665      0.057    -39.851      0.000      -2.378      -2.155\n",
      "word_freq_make           -5.0935      3.852     -1.322      0.186     -12.643       2.456\n",
      "word_freq_all             5.9660      0.719      8.301      0.000       4.557       7.375\n",
      "word_freq_our            -3.1607      3.407     -0.928      0.353      -9.837       3.516\n",
      "word_freq_free           30.6567      2.325     13.185      0.000      26.100      35.214\n",
      "word_freq_meeting      -355.2737   1.48e+04     -0.024      0.981   -2.94e+04    2.86e+04\n",
      "word_freq_re              1.0368      0.521      1.988      0.047       0.015       2.059\n",
      "word_freq_edu             0.1133      3.141      0.036      0.971      -6.043       6.269\n",
      "word_freq_semicolon     -39.6419      9.498     -4.174      0.000     -58.258     -21.026\n",
      "word_freq_exclamation     6.4094      0.660      9.710      0.000       5.116       7.703\n",
      "word_freq_hashtag        22.0823     11.556      1.911      0.056      -0.566      44.731\n",
      "=========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "mylogit = sm.Logit.from_formula(formula, data=spam_previous_words).fit()\n",
    "print(mylogit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad6a68",
   "metadata": {},
   "source": [
    "# Significance test of models\n",
    "\n",
    "Both models p-values are below the 0.05 treshold, so the null hypothesis can be rejected. It means that the model`s coefficients are jointly significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9fde79a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probit likelihood ratio test p-value: 9.630820582497978e-117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam_previous_words[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probit likelihood ratio test p-value:\", probit_lrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7788a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Logit likelihood ratio test p-value: 4.026157970994626e-119\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Probit(spam_previous_words[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d726f1",
   "metadata": {},
   "source": [
    "### Stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cf2d70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_probit = myprobit.pvalues\n",
    "spam_temp_probit = spam_previous_words.copy()\n",
    "\n",
    "while any(p_probit > 0.05):\n",
    "    worstp = p_probit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_probit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_probit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    myprobit = sm.Probit.from_formula(formula, data=spam_temp_probit).fit()\n",
    "    p_probit = myprobit.pvalues\n",
    "    print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "607d7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_meeting\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346883\n",
      "         Iterations 10\n",
      "3885.6663210969095\n",
      "word_freq_edu\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346883\n",
      "         Iterations 10\n",
      "3883.6680761623174\n",
      "word_freq_our\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346967\n",
      "         Iterations 10\n",
      "3882.598757849926\n",
      "word_freq_make\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347171\n",
      "         Iterations 10\n",
      "3882.8707237137123\n",
      "word_freq_hashtag\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347500\n",
      "         Iterations 10\n",
      "3884.543201635922\n"
     ]
    }
   ],
   "source": [
    "p_logit = mylogit.pvalues\n",
    "spam_temp_logit = spam_previous_words.copy()\n",
    "\n",
    "while any(p_logit > 0.05):\n",
    "    worstp = p_logit.idxmax()\n",
    "    \n",
    "    print(worstp)\n",
    "    spam_temp_logit.drop(columns=worstp, inplace=True)\n",
    "    \n",
    "    formula = \"spam ~\"\n",
    "    \n",
    "    for column in spam_temp_logit.columns[1:]:\n",
    "        formula += f\" + {column}\"\n",
    "    \n",
    "    mylogit = sm.Logit.from_formula(formula, data=spam_temp_logit).fit()\n",
    "    p_logit = mylogit.pvalues\n",
    "    print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "94af9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                   1.1495e+05\n",
      "Time:                        12:55:29   Pearson chi2:                 5.62e+18\n",
      "No. Iterations:                   100                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       9.856e+13   2.73e+05   3.61e+08      0.000    9.86e+13    9.86e+13\n",
      "x1         -3.484e+12   1.45e+05   -2.4e+07      0.000   -3.48e+12   -3.48e+12\n",
      "x2         -2.524e+13   1.38e+04  -1.83e+09      0.000   -2.52e+13   -2.52e+13\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "743c26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       67420.\n",
      "Time:                        12:55:56   Pearson chi2:                 3.30e+18\n",
      "No. Iterations:                    69                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       7.703e+14   1.92e+06   4.01e+08      0.000     7.7e+14     7.7e+14\n",
      "x1          8.044e+14   8.78e+05   9.16e+08      0.000    8.04e+14    8.04e+14\n",
      "x2          7.201e+12   3.45e+04   2.09e+08      0.000     7.2e+12     7.2e+12\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# Linktest for probit model - after stepwise regression\n",
    "linktest_result_logit = linktest_logit(mylogit)\n",
    "print(linktest_result_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d880b",
   "metadata": {},
   "source": [
    "### Interaction terms\n",
    "---\n",
    "We include the interaction terms from the previous research. The variables that were discarded due to low variances are excluded from the interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f605ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spam', 'word_freq_make', 'word_freq_all', 'word_freq_our',\n",
       "       'word_freq_free', 'word_freq_meeting', 'word_freq_re', 'word_freq_edu',\n",
       "       'word_freq_semicolon', 'word_freq_exclamation', 'word_freq_hashtag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_previous_words.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c2a6d",
   "metadata": {},
   "source": [
    "### Logit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "306bd4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                                                      0.000000e+00\n",
      "word_freq_make                                                 2.380242e-01\n",
      "word_freq_our                                                  3.489793e-01\n",
      "word_freq_make:word_freq_our                                   9.999865e-01\n",
      "word_freq_free                                                 4.468356e-47\n",
      "word_freq_meeting                                              9.997683e-01\n",
      "word_freq_edu                                                  9.950311e-01\n",
      "word_freq_semicolon                                            2.518382e-02\n",
      "word_freq_exclamation                                          2.167942e-20\n",
      "word_freq_semicolon:word_freq_exclamation                      9.999221e-01\n",
      "word_freq_hashtag                                              3.630297e-01\n",
      "word_freq_semicolon:word_freq_hashtag                          9.987517e-01\n",
      "word_freq_exclamation:word_freq_hashtag                        9.999173e-01\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag    9.999374e-01\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~ word_freq_make * word_freq_our  +  word_freq_free + word_freq_meeting  + word_freq_edu +  word_freq_semicolon * word_freq_exclamation * word_freq_hashtag\"\n",
    "\n",
    "mylogit = sm.formula.glm(formula_interactions, data=spam_previous_words, family=sm.families.Binomial(sm.genmod.families.links.logit())).fit()\n",
    "\n",
    "p = mylogit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "213a5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make:word_freq_our\n",
      "word_freq_make:word_freq_our\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5559\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3898.2\n",
      "Time:                        12:50:27   Pearson chi2:                 8.24e+03\n",
      "No. Iterations:                    28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================================================\n",
      "                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                      -2.1006      0.048    -43.865      0.000      -2.194      -2.007\n",
      "word_freq_make                                                 -4.7996      3.798     -1.264      0.206     -12.243       2.644\n",
      "word_freq_our                                                  -3.3658      3.349     -1.005      0.315      -9.930       3.199\n",
      "word_freq_free                                                 32.3717      2.246     14.414      0.000      27.970      36.773\n",
      "word_freq_meeting                                            -747.4871   2.57e+06     -0.000      1.000   -5.05e+06    5.05e+06\n",
      "word_freq_edu                                                   0.0195      3.063      0.006      0.995      -5.985       6.024\n",
      "word_freq_semicolon                                           -18.6887      8.347     -2.239      0.025     -35.049      -2.328\n",
      "word_freq_exclamation                                           6.0588      0.655      9.249      0.000       4.775       7.343\n",
      "word_freq_semicolon:word_freq_exclamation                   -3.003e+04   3.08e+08  -9.76e-05      1.000   -6.03e+08    6.03e+08\n",
      "word_freq_hashtag                                              11.8776     13.064      0.909      0.363     -13.727      37.482\n",
      "word_freq_semicolon:word_freq_hashtag                       -3.575e+04   2.29e+07     -0.002      0.999   -4.48e+07    4.48e+07\n",
      "word_freq_exclamation:word_freq_hashtag                      1.905e+04   1.84e+08      0.000      1.000    -3.6e+08    3.61e+08\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag  6.305e+05   8.03e+09   7.85e-05      1.000   -1.57e+10    1.57e+10\n",
      "===============================================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5560\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3898.2\n",
      "Time:                        12:50:27   Pearson chi2:                 8.24e+03\n",
      "No. Iterations:                    28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================\n",
      "                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    -2.1006      0.048    -43.865      0.000      -2.194      -2.007\n",
      "word_freq_make                               -4.7996      3.798     -1.264      0.206     -12.243       2.644\n",
      "word_freq_our                                -3.3658      3.349     -1.005      0.315      -9.930       3.199\n",
      "word_freq_free                               32.3717      2.246     14.414      0.000      27.970      36.773\n",
      "word_freq_meeting                          -747.4928   2.57e+06     -0.000      1.000   -5.05e+06    5.05e+06\n",
      "word_freq_edu                                 0.0195      3.063      0.006      0.995      -5.985       6.024\n",
      "word_freq_semicolon                         -18.6887      8.347     -2.239      0.025     -35.049      -2.328\n",
      "word_freq_exclamation                         6.0588      0.655      9.249      0.000       4.775       7.343\n",
      "word_freq_semicolon:word_freq_exclamation -2.794e+04   1.31e+08     -0.000      1.000   -2.57e+08    2.57e+08\n",
      "word_freq_hashtag                            11.8776     13.064      0.909      0.363     -13.727      37.482\n",
      "word_freq_semicolon:word_freq_hashtag     -3.583e+04   2.33e+07     -0.002      0.999   -4.57e+07    4.56e+07\n",
      "word_freq_exclamation:word_freq_hashtag    6.527e+04   2.64e+08      0.000      1.000   -5.17e+08    5.18e+08\n",
      "=============================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_exclamation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5561\n",
      "Model Family:                Binomial   Df Model:                           10\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3900.9\n",
      "Time:                        12:50:27   Pearson chi2:                 8.32e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -2.1013      0.048    -43.867      0.000      -2.195      -2.007\n",
      "word_freq_make                             -4.8058      3.801     -1.264      0.206     -12.255       2.644\n",
      "word_freq_our                              -3.3632      3.350     -1.004      0.315      -9.928       3.202\n",
      "word_freq_free                             32.3898      2.246     14.419      0.000      27.987      36.793\n",
      "word_freq_meeting                        -782.0481   4.23e+06     -0.000      1.000    -8.3e+06     8.3e+06\n",
      "word_freq_edu                               0.0210      3.063      0.007      0.995      -5.981       6.023\n",
      "word_freq_semicolon                       -22.6606      9.100     -2.490      0.013     -40.496      -4.825\n",
      "word_freq_exclamation                       6.0434      0.655      9.226      0.000       4.760       7.327\n",
      "word_freq_hashtag                          11.8830     13.064      0.910      0.363     -13.721      37.487\n",
      "word_freq_semicolon:word_freq_hashtag   -5.283e+04   4.11e+07     -0.001      0.999   -8.05e+07    8.04e+07\n",
      "word_freq_exclamation:word_freq_hashtag  1.548e+04   1.28e+07      0.001      0.999   -2.51e+07    2.52e+07\n",
      "===========================================================================================================\n",
      "nan\n",
      "word_freq_meeting\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5562\n",
      "Model Family:                Binomial   Df Model:                            9\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3910.6\n",
      "Time:                        12:50:27   Pearson chi2:                 8.42e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -2.1117      0.048    -44.122      0.000      -2.206      -2.018\n",
      "word_freq_make                             -4.7352      3.796     -1.247      0.212     -12.175       2.705\n",
      "word_freq_our                              -3.2901      3.346     -0.983      0.325      -9.848       3.268\n",
      "word_freq_free                             32.5159      2.249     14.460      0.000      28.108      36.923\n",
      "word_freq_edu                               0.0382      3.056      0.013      0.990      -5.951       6.027\n",
      "word_freq_semicolon                       -22.5158      9.086     -2.478      0.013     -40.325      -4.707\n",
      "word_freq_exclamation                       6.0984      0.655      9.306      0.000       4.814       7.383\n",
      "word_freq_hashtag                          11.9673     13.064      0.916      0.360     -13.638      37.573\n",
      "word_freq_semicolon:word_freq_hashtag   -5.284e+04   4.11e+07     -0.001      0.999   -8.05e+07    8.04e+07\n",
      "word_freq_exclamation:word_freq_hashtag  1.548e+04   1.28e+07      0.001      0.999   -2.51e+07    2.52e+07\n",
      "===========================================================================================================\n",
      "nan\n",
      "word_freq_exclamation:word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5563\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3921.0\n",
      "Time:                        12:50:27   Pearson chi2:                 8.40e+03\n",
      "No. Iterations:                    28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================================\n",
      "                                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Intercept                                -2.1091      0.048    -44.115      0.000      -2.203      -2.015\n",
      "word_freq_make                           -4.7670      3.798     -1.255      0.209     -12.211       2.677\n",
      "word_freq_our                            -3.3150      3.348     -0.990      0.322      -9.877       3.247\n",
      "word_freq_free                           32.4733      2.248     14.447      0.000      28.068      36.879\n",
      "word_freq_edu                             0.0334      3.058      0.011      0.991      -5.960       6.027\n",
      "word_freq_semicolon                     -22.5571      9.091     -2.481      0.013     -40.374      -4.740\n",
      "word_freq_exclamation                     6.1220      0.655      9.347      0.000       4.838       7.406\n",
      "word_freq_hashtag                        32.7669     15.481      2.117      0.034       2.425      63.109\n",
      "word_freq_semicolon:word_freq_hashtag -3.591e+04    2.3e+07     -0.002      0.999   -4.51e+07    4.51e+07\n",
      "=========================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5564\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1963.7\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3927.4\n",
      "Time:                        12:50:27   Pearson chi2:                 9.57e+03\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1064      0.048    -44.119      0.000      -2.200      -2.013\n",
      "word_freq_make           -4.7609      3.796     -1.254      0.210     -12.201       2.679\n",
      "word_freq_our            -3.3389      3.349     -0.997      0.319      -9.903       3.226\n",
      "word_freq_free           32.4208      2.245     14.440      0.000      28.020      36.821\n",
      "word_freq_edu             0.0286      3.060      0.009      0.993      -5.969       6.026\n",
      "word_freq_semicolon     -40.3730      9.572     -4.218      0.000     -59.133     -21.613\n",
      "word_freq_exclamation     6.1161      0.654      9.345      0.000       4.833       7.399\n",
      "word_freq_hashtag        21.6407     11.722      1.846      0.065      -1.335      44.616\n",
      "=========================================================================================\n",
      "3943.37126789368\n",
      "word_freq_edu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5565\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1963.7\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3927.4\n",
      "Time:                        12:50:27   Pearson chi2:                 9.57e+03\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1064      0.048    -44.133      0.000      -2.200      -2.013\n",
      "word_freq_make           -4.7607      3.796     -1.254      0.210     -12.201       2.679\n",
      "word_freq_our            -3.3390      3.349     -0.997      0.319      -9.904       3.225\n",
      "word_freq_free           32.4206      2.245     14.440      0.000      28.020      36.821\n",
      "word_freq_semicolon     -40.3732      9.572     -4.218      0.000     -59.134     -21.613\n",
      "word_freq_exclamation     6.1161      0.654      9.345      0.000       4.833       7.399\n",
      "word_freq_hashtag        21.6406     11.722      1.846      0.065      -1.335      44.616\n",
      "=========================================================================================\n",
      "3941.3713547883717\n",
      "word_freq_our\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5566\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1964.3\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3928.5\n",
      "Time:                        12:50:27   Pearson chi2:                 9.50e+03\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1120      0.047    -44.495      0.000      -2.205      -2.019\n",
      "word_freq_make           -4.9719      3.750     -1.326      0.185     -12.321       2.377\n",
      "word_freq_free           32.3465      2.250     14.378      0.000      27.937      36.756\n",
      "word_freq_semicolon     -40.3446      9.566     -4.217      0.000     -59.094     -21.595\n",
      "word_freq_exclamation     6.1232      0.654      9.358      0.000       4.841       7.406\n",
      "word_freq_hashtag        21.6908     11.727      1.850      0.064      -1.294      44.675\n",
      "=========================================================================================\n",
      "3940.519938984351\n",
      "word_freq_make\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5567\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1965.3\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3930.7\n",
      "Time:                        12:50:27   Pearson chi2:                 9.54e+03\n",
      "No. Iterations:                     8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1188      0.047    -44.809      0.000      -2.211      -2.026\n",
      "word_freq_free           32.4098      2.251     14.399      0.000      27.998      36.821\n",
      "word_freq_semicolon     -40.3928      9.574     -4.219      0.000     -59.157     -21.629\n",
      "word_freq_exclamation     6.0898      0.653      9.331      0.000       4.811       7.369\n",
      "word_freq_hashtag        21.7735     11.735      1.855      0.064      -1.226      44.773\n",
      "=========================================================================================\n",
      "3940.673445820665\n",
      "word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5568\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1967.1\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3934.2\n",
      "Time:                        12:50:27   Pearson chi2:                 8.72e+03\n",
      "No. Iterations:                     9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.1164      0.047    -44.800      0.000      -2.209      -2.024\n",
      "word_freq_free           32.3828      2.251     14.389      0.000      27.972      36.794\n",
      "word_freq_semicolon     -33.1868      8.873     -3.740      0.000     -50.578     -15.795\n",
      "word_freq_exclamation     6.0833      0.653      9.323      0.000       4.804       7.362\n",
      "=========================================================================================\n",
      "3942.18274292718\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam_previous_words)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        mylogit = sm.GLM(spam['spam'], X, family=sm.families.Binomial(sm.families.links.logit())).fit()\n",
    "\n",
    "        print(mylogit.summary())\n",
    "        p = mylogit.pvalues\n",
    "        print(mylogit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c57d7e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 6\n",
      "Logit likelihood ratio test p-value: 2.183379900800917e-101\n",
      "LinkTest result                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3772.4\n",
      "Time:                        12:50:37   Pearson chi2:                 4.38e+14\n",
      "No. Iterations:                    11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2899      0.068      4.271      0.000       0.157       0.423\n",
      "x1             0.4763      0.030     16.022      0.000       0.418       0.535\n",
      "x2            -0.1311      0.013    -10.131      0.000      -0.156      -0.106\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "null_logit = sm.Logit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "logit_lrtest = stats.chi2.sf(2 * (mylogit.llf - null_logit.llf), 1)\n",
    "print(\"Logit likelihood ratio test p-value:\", logit_lrtest)\n",
    "\n",
    "linktest_result_logit = linktest_probit(mylogit)\n",
    "print(\"LinkTest result\", linktest_result_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df3885",
   "metadata": {},
   "source": [
    "### Probit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2f74f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                                                      0.000000e+00\n",
      "word_freq_make                                                 2.448583e-01\n",
      "word_freq_our                                                  3.505927e-01\n",
      "word_freq_make:word_freq_our                                   9.999939e-01\n",
      "word_freq_free                                                 2.505399e-37\n",
      "word_freq_meeting                                              9.998632e-01\n",
      "word_freq_edu                                                  9.929512e-01\n",
      "word_freq_semicolon                                            1.541134e-02\n",
      "word_freq_exclamation                                          7.412272e-23\n",
      "word_freq_semicolon:word_freq_exclamation                      9.999560e-01\n",
      "word_freq_hashtag                                              3.645956e-01\n",
      "word_freq_semicolon:word_freq_hashtag                          9.991605e-01\n",
      "word_freq_exclamation:word_freq_hashtag                        9.999523e-01\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag    9.999670e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula_interactions = \"spam ~ word_freq_make * word_freq_our  +  word_freq_free + word_freq_meeting  + word_freq_edu +  word_freq_semicolon * word_freq_exclamation * word_freq_hashtag\"\n",
    "myprobit = sm.formula.glm(formula_interactions, data=spam_previous_words, family=sm.families.Binomial(sm.genmod.families.links.probit())).fit()\n",
    "\n",
    "p = myprobit.pvalues\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2a8168a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make:word_freq_our\n",
      "word_freq_make:word_freq_our\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5559\n",
      "Model Family:                Binomial   Df Model:                           12\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3907.4\n",
      "Time:                        12:29:47   Pearson chi2:                 6.19e+03\n",
      "No. Iterations:                    30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================================================\n",
      "                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                      -1.2403      0.025    -49.379      0.000      -1.290      -1.191\n",
      "word_freq_make                                                 -2.3650      1.844     -1.282      0.200      -5.980       1.250\n",
      "word_freq_our                                                  -1.6958      1.636     -1.036      0.300      -4.903       1.511\n",
      "word_freq_free                                                 14.9663      1.172     12.768      0.000      12.669      17.264\n",
      "word_freq_meeting                                            -192.5882   1.12e+06     -0.000      1.000    -2.2e+06     2.2e+06\n",
      "word_freq_edu                                                   0.0167      1.600      0.010      0.992      -3.119       3.152\n",
      "word_freq_semicolon                                            -8.0336      3.315     -2.423      0.015     -14.531      -1.536\n",
      "word_freq_exclamation                                           3.7869      0.385      9.836      0.000       3.032       4.541\n",
      "word_freq_semicolon:word_freq_exclamation                   -7230.7266   1.31e+08  -5.51e-05      1.000   -2.57e+08    2.57e+08\n",
      "word_freq_hashtag                                               7.2332      7.983      0.906      0.365      -8.414      22.880\n",
      "word_freq_semicolon:word_freq_hashtag                       -9445.0476   8.98e+06     -0.001      0.999   -1.76e+07    1.76e+07\n",
      "word_freq_exclamation:word_freq_hashtag                      5460.5579   9.14e+07   5.97e-05      1.000   -1.79e+08    1.79e+08\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag  1.436e+05   3.47e+09   4.14e-05      1.000   -6.79e+09    6.79e+09\n",
      "===============================================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5560\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3907.4\n",
      "Time:                        12:29:47   Pearson chi2:                 6.19e+03\n",
      "No. Iterations:                    30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================\n",
      "                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    -1.2403      0.025    -49.379      0.000      -1.290      -1.191\n",
      "word_freq_make                               -2.3650      1.844     -1.282      0.200      -5.980       1.250\n",
      "word_freq_our                                -1.6958      1.636     -1.036      0.300      -4.903       1.511\n",
      "word_freq_free                               14.9663      1.172     12.768      0.000      12.669      17.264\n",
      "word_freq_meeting                          -192.5892   1.12e+06     -0.000      1.000    -2.2e+06     2.2e+06\n",
      "word_freq_edu                                 0.0167      1.600      0.010      0.992      -3.119       3.152\n",
      "word_freq_semicolon                          -8.0336      3.315     -2.423      0.015     -14.531      -1.536\n",
      "word_freq_exclamation                         3.7869      0.385      9.836      0.000       3.032       4.541\n",
      "word_freq_semicolon:word_freq_exclamation -6964.2429   6.33e+07     -0.000      1.000   -1.24e+08    1.24e+08\n",
      "word_freq_hashtag                             7.2332      7.983      0.906      0.365      -8.414      22.880\n",
      "word_freq_semicolon:word_freq_hashtag     -9461.0727   9.21e+06     -0.001      0.999   -1.81e+07     1.8e+07\n",
      "word_freq_exclamation:word_freq_hashtag     1.65e+04   1.27e+08      0.000      1.000   -2.48e+08    2.48e+08\n",
      "=============================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_exclamation\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5561\n",
      "Model Family:                Binomial   Df Model:                           10\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3910.6\n",
      "Time:                        12:29:47   Pearson chi2:                 6.25e+03\n",
      "No. Iterations:                    30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -1.2408      0.025    -49.391      0.000      -1.290      -1.192\n",
      "word_freq_make                             -2.3688      1.846     -1.283      0.199      -5.987       1.249\n",
      "word_freq_our                              -1.6936      1.636     -1.035      0.301      -4.900       1.513\n",
      "word_freq_free                             14.9741      1.172     12.773      0.000      12.676      17.272\n",
      "word_freq_meeting                        -192.5654   1.12e+06     -0.000      1.000    -2.2e+06     2.2e+06\n",
      "word_freq_edu                               0.0181      1.599      0.011      0.991      -3.116       3.152\n",
      "word_freq_semicolon                        -9.4656      3.511     -2.696      0.007     -16.347      -2.584\n",
      "word_freq_exclamation                       3.7737      0.385      9.806      0.000       3.019       4.528\n",
      "word_freq_hashtag                           7.2374      7.983      0.907      0.365      -8.409      22.884\n",
      "word_freq_semicolon:word_freq_hashtag     -1.6e+04   9.09e+06     -0.002      0.999   -1.78e+07    1.78e+07\n",
      "word_freq_exclamation:word_freq_hashtag  4751.2625   2.85e+06      0.002      0.999   -5.57e+06    5.58e+06\n",
      "===========================================================================================================\n",
      "nan\n",
      "word_freq_meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5562\n",
      "Model Family:                Binomial   Df Model:                            9\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3920.1\n",
      "Time:                        12:29:48   Pearson chi2:                 6.31e+03\n",
      "No. Iterations:                    30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -1.2464      0.025    -49.722      0.000      -1.296      -1.197\n",
      "word_freq_make                             -2.3281      1.843     -1.263      0.207      -5.940       1.284\n",
      "word_freq_our                              -1.6532      1.634     -1.012      0.312      -4.856       1.549\n",
      "word_freq_free                             15.0197      1.173     12.806      0.000      12.721      17.319\n",
      "word_freq_edu                               0.0279      1.596      0.017      0.986      -3.101       3.157\n",
      "word_freq_semicolon                        -9.3996      3.506     -2.681      0.007     -16.271      -2.528\n",
      "word_freq_exclamation                       3.8059      0.385      9.889      0.000       3.052       4.560\n",
      "word_freq_hashtag                           7.2858      7.983      0.913      0.361      -8.361      22.933\n",
      "word_freq_semicolon:word_freq_hashtag   -1.601e+04    9.1e+06     -0.002      0.999   -1.78e+07    1.78e+07\n",
      "word_freq_exclamation:word_freq_hashtag  4753.0184   2.85e+06      0.002      0.999   -5.58e+06    5.59e+06\n",
      "===========================================================================================================\n",
      "nan\n",
      "word_freq_exclamation:word_freq_hashtag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5563\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3930.4\n",
      "Time:                        12:29:48   Pearson chi2:                 6.31e+03\n",
      "No. Iterations:                    30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================================\n",
      "                                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Intercept                                -1.2452      0.025    -49.706      0.000      -1.294      -1.196\n",
      "word_freq_make                           -2.3437      1.844     -1.271      0.204      -5.958       1.271\n",
      "word_freq_our                            -1.6668      1.635     -1.019      0.308      -4.871       1.538\n",
      "word_freq_free                           15.0064      1.173     12.797      0.000      12.708      17.305\n",
      "word_freq_edu                             0.0254      1.597      0.016      0.987      -3.105       3.156\n",
      "word_freq_semicolon                      -9.4162      3.507     -2.685      0.007     -16.290      -2.542\n",
      "word_freq_exclamation                     3.8202      0.385      9.929      0.000       3.066       4.574\n",
      "word_freq_hashtag                        16.6654      8.077      2.063      0.039       0.835      32.495\n",
      "word_freq_semicolon:word_freq_hashtag -9529.7141   8.97e+06     -0.001      0.999   -1.76e+07    1.76e+07\n",
      "=========================================================================================================\n",
      "nan\n",
      "word_freq_semicolon:word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5564\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1969.5\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3939.0\n",
      "Time:                        12:29:48   Pearson chi2:                 7.78e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.2435      0.025    -49.716      0.000      -1.293      -1.194\n",
      "word_freq_make           -2.3519      1.845     -1.275      0.202      -5.968       1.264\n",
      "word_freq_our            -1.6823      1.636     -1.028      0.304      -4.889       1.524\n",
      "word_freq_free           14.9825      1.171     12.793      0.000      12.687      17.278\n",
      "word_freq_edu             0.0223      1.598      0.014      0.989      -3.110       3.155\n",
      "word_freq_semicolon     -15.8171      3.753     -4.214      0.000     -23.173      -8.461\n",
      "word_freq_exclamation     3.8129      0.384      9.925      0.000       3.060       4.566\n",
      "word_freq_hashtag         8.4236      6.310      1.335      0.182      -3.944      20.792\n",
      "=========================================================================================\n",
      "3954.9958787669793\n",
      "word_freq_edu\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5565\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1969.5\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3939.0\n",
      "Time:                        12:29:48   Pearson chi2:                 7.78e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.2435      0.025    -49.732      0.000      -1.293      -1.194\n",
      "word_freq_make           -2.3515      1.845     -1.275      0.202      -5.967       1.264\n",
      "word_freq_our            -1.6824      1.636     -1.028      0.304      -4.889       1.524\n",
      "word_freq_free           14.9825      1.171     12.793      0.000      12.687      17.278\n",
      "word_freq_semicolon     -15.8172      3.753     -4.214      0.000     -23.174      -8.461\n",
      "word_freq_exclamation     3.8128      0.384      9.925      0.000       3.060       4.566\n",
      "word_freq_hashtag         8.4235      6.310      1.335      0.182      -3.945      20.792\n",
      "=========================================================================================\n",
      "3952.996044937106\n",
      "word_freq_our\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5566\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1970.0\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3940.0\n",
      "Time:                        12:29:48   Pearson chi2:                 7.76e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.2464      0.025    -50.136      0.000      -1.295      -1.198\n",
      "word_freq_make           -2.4491      1.835     -1.335      0.182      -6.045       1.147\n",
      "word_freq_free           14.9632      1.171     12.779      0.000      12.668      17.258\n",
      "word_freq_semicolon     -15.8034      3.751     -4.213      0.000     -23.155      -8.452\n",
      "word_freq_exclamation     3.8133      0.384      9.929      0.000       3.061       4.566\n",
      "word_freq_hashtag         8.4424      6.311      1.338      0.181      -3.926      20.811\n",
      "=========================================================================================\n",
      "3952.0384633275626\n",
      "word_freq_make\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5567\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1971.0\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3941.9\n",
      "Time:                        12:29:48   Pearson chi2:                 7.79e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.2501      0.025    -50.506      0.000      -1.299      -1.202\n",
      "word_freq_free           14.9900      1.171     12.802      0.000      12.695      17.285\n",
      "word_freq_semicolon     -15.8089      3.752     -4.213      0.000     -23.163      -8.455\n",
      "word_freq_exclamation     3.8021      0.383      9.918      0.000       3.051       4.554\n",
      "word_freq_hashtag         8.4708      6.309      1.343      0.179      -3.894      20.836\n",
      "=========================================================================================\n",
      "3951.9493683519154\n",
      "word_freq_hashtag\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5568\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1972.0\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       3943.9\n",
      "Time:                        12:29:49   Pearson chi2:                 6.74e+03\n",
      "No. Iterations:                    29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.2492      0.025    -50.483      0.000      -1.298      -1.201\n",
      "word_freq_free           14.9842      1.171     12.796      0.000      12.689      17.279\n",
      "word_freq_semicolon     -13.3560      3.128     -4.270      0.000     -19.486      -7.226\n",
      "word_freq_exclamation     3.8018      0.383      9.917      0.000       3.050       4.553\n",
      "=========================================================================================\n",
      "3951.9129573255277\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while any(p > 0.05):\n",
    "    worstp = p.idxmax()\n",
    "    print(worstp)\n",
    "\n",
    "    if i == 1:\n",
    "        # Remove the outcome variable from the formula\n",
    "        formula_interactions = formula_interactions.replace(\"spam ~ \", \"\")\n",
    "\n",
    "        # Create the design matrix with interaction terms\n",
    "        X = patsy.dmatrix(formula_interactions, data=spam_previous_words)\n",
    "\n",
    "        # Convert the design matrix to a DataFrame\n",
    "        X = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "        i=2\n",
    "    else:\n",
    "        X = X.drop(worstp, axis=1)\n",
    "        X_names = ['Intercept'] + list(X.columns)[1:]\n",
    "        X.columns = X_names\n",
    "\n",
    "        myprobit = sm.GLM(spam['spam'], X, family=sm.families.Binomial(sm.families.links.probit())).fit()\n",
    "\n",
    "        print(myprobit.summary())\n",
    "        p = myprobit.pvalues\n",
    "        print(myprobit.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5f4aa3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394038\n",
      "         Iterations 5\n",
      "Probitlikelihood ratio test p-value: nan\n",
      "LinkTest result                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 5572\n",
      "Model:                            GLM   Df Residuals:                     5569\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                 probit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 18 Jun 2023   Deviance:                       69170.\n",
      "Time:                        12:50:42   Pearson chi2:                 3.38e+18\n",
      "No. Iterations:                    14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.541e+14   1.67e+05  -9.21e+08      0.000   -1.54e+14   -1.54e+14\n",
      "x1          5.476e+13   6.82e+04   8.03e+08      0.000    5.48e+13    5.48e+13\n",
      "x2          1.432e+12   2335.758   6.13e+08      0.000    1.43e+12    1.43e+12\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: divide by zero encountered in log\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:947: RuntimeWarning: invalid value encountered in multiply\n",
      "  y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "null_probit = sm.Probit(spam[\"spam\"], sm.add_constant(pd.Series([1] * len(spam_previous_words)))).fit()\n",
    "probit_lrtest = stats.chi2.sf(2 * (myprobit.llf - null_probit.llf), 1)\n",
    "print(\"Probitlikelihood ratio test p-value:\", probit_lrtest)\n",
    "\n",
    "linktest_result_probit = linktest_probit(myprobit)\n",
    "print(\"LinkTest result\", linktest_result_probit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ef986",
   "metadata": {},
   "source": [
    "### Other goodness of fit tests\n",
    "\n",
    "As in previous study the Link Test and LR test draw attention to the logit model with interactions that was good specified and significant\n",
    "Now let us perform other tests for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4cd3463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Goodness-of-Fit Test:\n",
      "Logit | Deviance:  3898.0927718622916\n",
      "Probit | Goodness-of-Fit Test:\n",
      "Probit | Deviance:  3943.9129573255277\n"
     ]
    }
   ],
   "source": [
    "gof_results = mylogit.deviance\n",
    "print(\"Logit | Goodness-of-Fit Test:\")\n",
    "print(\"Logit | Deviance: \", gof_results)\n",
    "\n",
    "gof_results = myprobit.deviance\n",
    "print(\"Probit | Goodness-of-Fit Test:\")\n",
    "print(\"Probit | Deviance: \", gof_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2f466bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit | Pseudo R-squared:  nan\n",
      "Probit | Pseudo R-squared:  0.10185221800250643\n"
     ]
    }
   ],
   "source": [
    "pseudo_r2 = 1 - (mylogit.llf / mylogit.llnull)\n",
    "print(\"Logit | Pseudo R-squared: \", pseudo_r2)\n",
    "\n",
    "pseudo_r2 = 1 - (myprobit.llf / myprobit.llnull)\n",
    "print(\"Probit | Pseudo R-squared: \", pseudo_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "35f7f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1810: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1863: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5192/2656749956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculating marginal effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmeff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mformula_interactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspam_previous_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logit | Marginal Effects:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m     def fit(self, start_params=None, method='newton', maxiter=35,\n\u001b[0;32m   1973\u001b[0m             full_output=1, disp=1, callback=None, **kwargs):\n\u001b[1;32m-> 1974\u001b[1;33m         bnryfit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                               \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                               \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mpass\u001b[0m  \u001b[1;31m# TODO: make a function factory to have multiple call-backs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         mlefit = super().fit(start_params=start_params,\n\u001b[0m\u001b[0;32m    228\u001b[0m                              \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                              \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Calculating marginal effects\n",
    "meff = smf.logit( formula_interactions, data=spam_previous_words).fit()\n",
    "print(\"Logit | Marginal Effects:\")\n",
    "print(meff.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f495516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 6\n",
      "Probit | Marginal Effects:\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   spam   No. Observations:                 5572\n",
      "Model:                         Probit   Df Residuals:                     5558\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Sun, 18 Jun 2023   Pseudo R-squ.:                     nan\n",
      "Time:                        12:37:50   Log-Likelihood:                    nan\n",
      "converged:                       True   LL-Null:                       -2195.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "===============================================================================================================================\n",
      "                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_make                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_our                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_make:word_freq_our                                       nan        nan        nan        nan         nan         nan\n",
      "word_freq_free                                                     nan        nan        nan        nan         nan         nan\n",
      "word_freq_meeting                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_edu                                                      nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon                                                nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation                                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation                          nan        nan        nan        nan         nan         nan\n",
      "word_freq_hashtag                                                  nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_hashtag                              nan        nan        nan        nan         nan         nan\n",
      "word_freq_exclamation:word_freq_hashtag                            nan        nan        nan        nan         nan         nan\n",
      "word_freq_semicolon:word_freq_exclamation:word_freq_hashtag        nan        nan        nan        nan         nan         nan\n",
      "===============================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2192: RuntimeWarning: invalid value encountered in true_divide\n",
      "  L = q*self.pdf(q*XB)/self.cdf(q*XB)\n"
     ]
    }
   ],
   "source": [
    "# Calculating marginal effects\n",
    "meff = smf.probit( formula_interactions, data=spam_previous_words).fit()\n",
    "print(\"Probit | Marginal Effects:\")\n",
    "print(meff.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
